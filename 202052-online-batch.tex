%
\subsubsection{Aprendizaje en línea y aprendizaje por época}
%
El aprendizaje en línea y el aprendizaje por época hacen referencia
a dos estrategias de entrenamiento que difieren según
el momento en que se efectúa la actualización de los pesos de la
red:
%
\begin{itemize}
\item En el aprendizaje en línea, o aprendizaje por patrón, se efectúa una
  actualización de los pesos de la red inmediatamente
  luego de calcular la salida y el
  error instantáneo de cada ejemplo del conjunto de aprendizaje.
  Esto implica que se efecúan tantas actualizaciones como ejemplos haya
  en el conjunto de entrenamiento.
  Este método funciona especialmente bien
  para grandes conjuntos de entrenamiento que contengan información
  redundante.
\item En el aprendizaje por época (\e{batch learning}),
  la actualización de los pesos de la red
  se efectúa una vez que han sido calculadas las salidas de todos los
  patrones en el conjunto de entrenamiento, minimizando la función de
  error promedio $\C{E}_{\T{av}}$.
\end{itemize}
%
Mientras que el aprendizaje en línea resulta idóneo para situaciones en donde
se requiere una adaptación continua de la máquina de aprendizaje, el
aprendizaje por época redunda en superficies de error más estables, ya que
se promedia todo el conjunto de datos.
En el presente trabajo, se considera en todos los casos el aprendizaje
por época.

%% Los procedimientos adaptativos descritos en adelante
%% utilizan este tipo de aprendizaje, ya que la información de gradiente
%% sumada contiene información más fiable acerca de la forma de la
%% función de error como un todo \cite{riedmiller}.  Algunos autores, sin
%% embargo, sugieren que la mejor técnica es la del aprendizaje en línea
%% \cite{haykin}.

%% %
%% \subsubsection{Técnicas adaptativas}
%% %
%% A la fecha, se han propuesto muchas técnicas para afrontar los
%% problemas inherentes del método de descenso por gradiente. La mayoría
%% tienen sus bases de la disciplina de la teoría de
%% optimización.

%% Estas técnicas se pueden dividir en dos
%% categorías. Aquellos algoritmos que utilizan un conocimiento global
%% del estado de la red como un todo, tal como la dirección del vector de
%% actualización de los pesos ``entero'', son llamadas técnicas globales.
%% Existen muchos ejemplos donde los algoritmos de aprendizaje utilizan el
%% conocimiento global \cite{salomon,moeller}.

%% Por contraste, las estrategias de adaptación locales se basan
%% únicamente en información específica a los pesos, tal como el
%% comportamiento temporal de la derivada parcial de este peso. El
%% enfoque local se relaciona más naturalmente con el concepro de
%% procesamiento distribuido en el que los cálculos pueden efectuarse en
%% paralelo.  Más aún, en muchos casos se encuentra que las estrategias
%% locales funcionan mucho mejor que las globales, a pesar del hecho que
%% utilizan menos información y de que normalmente son mucho más rápidas
%% y fáciles de calcular \cite{schiffmann}.
