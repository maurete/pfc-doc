%
\subsubsection{Rprop}
%
El algoritmo Rprop \cite{rprop} es una variante
heurística sencilla de la retropropagación clásica, que actualiza cada uno de
los pesos de la red de forma independiente.
%% A diferencia de los
%% algoritmos vistos anteriormente, Rprop considera únicamente el signo
%% del gradiente para cada peso, ignorando su magnitud.
Para cada peso $w_{ij}$, Rprop determina un valor de actualización
específico $\Delta{}w_{ij}$ según la siguiente regla basada en el
signo de la derivada parcial
%
\begin{align}
  \Delta{}w_{ij}(t) =
  \begin{cases}
    -\Delta_{ij}^{(t)}, & \T{si}\,\,\,\dpar{\C{E}}{w_{ij}}{}(t) > 0, \\
    +\Delta_{ij}^{(t)}, & \T{si}\,\,\,\dpar{\C{E}}{w_{ij}}{}(t) < 0, \\
    0, & \T{en otro caso}.
  \end{cases}
\end{align}
%
El algoritmo regula su funcionamiento mediante dos hiperparámetros,
$\Delta_0$ y $\Delta_{\max}$, que especifican respectivamente el valor
de inicialización de todos los $\Delta_{ij}$ y la magnitud máxima
permitida para cada $\Delta_{ij}$.  Los valores de cada $\Delta_{ij}$
se modifican en cada iteración según la regla
%
\begin{align}
  \Delta{}_{ij}^{(t)} \tab =
  \begin{cases}
    \eta^+\,\Delta_{ij}^{(t-1)}, & \T{si}\,\,\,\dpar{\C{E}}{w_{ij}}{} {(t-1)}
      \dpar{\C{E}}{w_{ij}}{} {(t)} > 0, \\
    \eta^-\,\Delta_{ij}^{(t-1)}, & \T{si}\,\,\,\dpar{\C{E}}{w_{ij}}{} {(t-1)}
      \dpar{\C{E}}{w_{ij}}{} {(t)} < 0, \\
    \Delta_{ij}^{(t-1)}, & \T{en otro caso}.
  \end{cases}
  \tabs
  \begin{split}
    \eta^-=0.5, \\
    \eta^+=1.2.
  \end{split}
\end{align}
%
El algoritmo Rprop es una de las técnicas más rápidas
y más populares para el entrenamiento del perceptrón multicapa.
Dada su estabilidad, la elección de los hiperparámetros
$\Delta_{0}$ y $\Delta_{\max}$ no es crítica, y en general
se utilizan los valores preestablecidos $\Delta_{0}=0.1$ y
$\Delta_{\max}=50$.
