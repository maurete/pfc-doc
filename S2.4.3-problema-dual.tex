%
%
\subsection{Formulación dual}
%
El problema (\ref{e2:svm-problem-basic}) intenta encontrar el mínimo
de una función cuadrática simple con restricciones ``complejas''
${y}_i(\ww^T\BPhi(\xx_i)+b)\geq{}1$.  Utilizando la técnica de los
multiplicadores de Lagrange \cite{bottou,kkt}, resulta posible obtener
una fomulación alternativa del problema, con restricciones simples,
cuya conveniencia será aparente con la introducción del concepto de
núcleos.

La técnica de los multiplicadores de Lagrange permite incorporar las
restricciones del problema dentro de la función a optimizar.  En
primer lugar, se define el funcional lagrangiano
%
\begin{align}\label{e2:lagrangian}
  \C{L}(\ww,b,\Balpha) = \frac{1}{2} \|\ww\|^2 + \sum_{i=1}^{\ell}
  \alpha_i (1-y_i(\langle\ww,\BPhi(\xx)\rangle+b)).
\end{align}
%
Como se puede ver, el funcional $\C{L}$ es la función a optimizar más
las restricciones ${y}_if_i\geq{}1$ en forma normalizada $g(\xx)\leq0$
y multiplicadas por las ``variables de holgura'' $\alpha_i$,
denominadas \e{multiplicadores de Lagrange}. A partir del lagrangiano
se plantea la formulación \emph{dual} del problema
%
\begin{align}\label{e2:svm-problem-dual}
  \begin{split}
    \max_\alpha \tabs\quad f(\Balpha) = \min_{\ww,b} \C{L}(\ww,b,\Balpha)\\
    \T{sujeto a} \tabs\quad \alpha_i \geq 0\T{ para todo } i\in\{1,\ldots,\ell\}
  \end{split}
\end{align}
%
Obsérvese que en este problema las restricciones son más sencillas y
aplican únicamente a los multiplicadores de Lagrange. Una condición
necesaria para la existencia de los multiplicadores $\alpha_i$ es que
la función objetivo del problema (\ref{e2:svm-problem-basic}) sea
continuamente derivable en las cercanías del mínimo local $(\ww^*,b^*)$.
\hl{citar condiciones KKT}
Además, dado que $(\ww^*,b^*)$ es un mínimo local, puede verse que
%
\begin{align}\label{e2:lagrangian-w}
  \evalen{\dpar{\C{L}(\ww,b,\Balpha)}{\ww}{}}{\ww=\ww^*}
    &=\ww^*-\sum_{i=1}^\ell y_i\alpha_i\BPhi(\xx_i) = 0
    &\Rightarrow \ww^* = \sum_{i=1}^\ell y_i\alpha_i\BPhi(\xx_i)
  \\
  \label{e2:lagrangian-sum-yalpha}
  \evalen{\dpar{\C{L}(\ww,b,\Balpha)}{b}{}}{b=b^*}
    &=-\sum_{i=1}^\ell y_i\alpha_i = 0
      &\Rightarrow \sum_{i=1}^\ell y_i\alpha_i = \yy^T\Balpha = 0.
\end{align}
%
Reemplazando (\ref{e2:lagrangian-w}) y
(\ref{e2:lagrangian-sum-yalpha}) en la
\iflatexml{}Ecuación~\ref{e2:lagrangian}\else\autoref{e2:lagrangian}\fi
el lagrangiano puede escribirse
%
\begin{align*}
  \C{L}(\ww,b,\Balpha)
  & = 
    \frac{1}{2}\sum_{i=1}^\ell\sum_{j=1}^\ell y_iy_j\alpha_i\alpha_j
    \langle\BPhi(\xx_i),\BPhi(\xx_j)\rangle \\
    &\qquad\qquad +
    \sum_{i=1}^{\ell} \alpha_i \left(1-y_i\left(\left\langle
    \sum_{j=1}^\ell y_j\alpha_j\BPhi(\xx_j) ,\BPhi(\xx_i)\right\rangle
    +b\right)\right)\\
  & = 
    -\frac{1}{2}\sum_{i=1}^\ell\sum_{j=1}^\ell y_iy_j\alpha_i\alpha_j
    \langle\BPhi(\xx_i),\BPhi(\xx_j)\rangle +
    \sum_{i=1}^{\ell} \alpha_i  - b \sum_{i=1}^\ell y_i\alpha_i \\
 & = 
    -\frac{1}{2}\sum_{i=1}^\ell\sum_{j=1}^\ell y_iy_j\alpha_i\alpha_j
    \langle\BPhi(\xx_i),\BPhi(\xx_j)\rangle +
    \sum_{i=1}^{\ell} \alpha_i  .
\end{align*}
%
Con este resultado, se han eliminado las referencias a las variables
originales $(\ww,b)$, quedando el problema únicamente definido en
términos de los multiplicadores de Lagrange $\alpha_i$:
%
\begin{align}
  \begin{split}
    \max_\alpha &\quad
    -\frac{1}{2}\sum_{i=1}^\ell\sum_{j=1}^\ell y_iy_j\alpha_i\alpha_j
    \langle \BPhi(\xx_i),\BPhi(\xx_j) \rangle +
    \sum_{i=1}^{\ell} \alpha_i \\
    \T{sujeto a} &\quad \yy^T\Balpha = 0, \\
    &\quad \alpha_i \geq 0\T{ para todo } i\in\{1,\ldots,\ell\}.
  \end{split}
  \label{e2:svm-problem-dual2}
\end{align}
%
Una vez encontrado $\Balpha^*$ que maximice el problema
(\ref{e2:svm-problem-dual}), la solución $(\ww^*,b^*)$ al problema
original. El vector $\ww^*$ se obtiene directamente de la
 \iflatexml{}Ecuación~\ref{e2:lagrangian-w}\else\autoref{e2:lagrangian-w}\fi:
%
\begin{align*}
  \ww^* = \sum_{i=1}^\ell y_i\alpha^*_i\BPhi(\xx_i).
\end{align*}
%
El cálculo de $b^*$ se deriva de las condiciones de complementariedad de
Karush-Kuhn-Tucker\footnote{Para una explicación detallada de las
  condiciones de Karush-Kuhn-Tucker, se refiere al lector a
  \hl{este libro}}: para todo $i\in\{1,\ldots,\ell\}$ se cumple que
$\alpha^*_i(1-y_i(\langle\ww^*,\BPhi(\xx_i)\rangle+b^*))=0$. Entonces,
para algún $\alpha^*_i\neq0$, se tiene
%
\begin{align}
  b^* = y_i - \langle\ww^*,\BPhi(\xx_i)\rangle .
\end{align}
%
En el caso de la SVM, la existencia de $\alpha^*_i\neq0$ está
garantizada siempre que el conjunto de entrenamiento tenga elementos
de ambas clases.
