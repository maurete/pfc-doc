%
%
%
\section{Hiperparámetros}
%
Hasta el momento se ha definido una máquina de aprendizaje
(\refer{eq:maqaprendizaje}) como un algoritmo que, dado un conjunto
de entrenamiento $D$, genera un modelo $h$ que relaciona valores de
entrada y de salida de una distribución desconocida $\nu$. En la
práctica, se encuentra que la mayoría de las técnicas de aprendizaje
requieren la especificación de parámetros adicionales que regulan el
proceso de aprendizaje.

Los parámetros que regulan la generación del modelo se denominan
\e{hiperparámetros}, marcando una distinción con los \e{parámetros}
del modelo $h$ --que se ajustan a partir del conjunto de datos
$D$. Dependiendo de la máquina de aprendizaje a utilizar, los
hiperparámetros pueden determinar, entre otros,
%
\begin{itemize}
\item la familia de modelos $H\subset\C{H}$ a utilizar,
\item los parámteros propios de la familia de modelos $H$,
\item la estrategia de optimización a utilizar durante el
  entrenamiento,
\item la topología de una red neuronal,
\item la \e{velocidad de aprendizaje},
\item la precisión requerida de la solución,
\item la \e{regularización} a aplicar al modelo.
\end{itemize}
%
Como se puede advertir, los elementos del conjunto de hiperparámetros
son de naturaleza variada: familias de funciones, vectores numéricos,
números reales son algunos de los tipos posibles.

Algunos hiperparámetros pueden ajustarse sin considerar los datos en
el conjunto de entrenamiento $D$, esto es, son independientes del
problema de clasificación; otros, en cambio, deberán ajustarse para
cada problema en particular. En adelante, se hace hincapié en aquellos
hiperparámetros numéricos dependientes del problema, expresados en
forma genérica como un vector
$\Btheta=(\theta_1,\theta_2,\ldots)$. La máquina de
aprendizaje puede escribirse como una transformación
%
\begin{align}
  A:\C{D}\times\C{P}\rightarrow\C{H},
\end{align}
%
esto es, un algoritmo que recibe como entrada los datos en $D\in\C{D}$
y un vector de hiperparámetros $\Btheta\in\C{P}$, para obtener
mediante entrenamiento un modelo óptimo $h\in\C{H}$.
%
%
\subsection{Selección automática de hiperparámetros}
%
Dado el conjunto de entrenamiento $D$, el objetivo de la selección
automática de hiperparámetros es encontrar los hiperparámetros óptimos
$\Btheta_*$ tal que el modelo resultante ajuste a los datos en $D$ con
mínimo error (de generalización).

En general, un algoritmo que implementa selección automática de
hiperparámetros sigue un esquema iterativo en el cual, partiendo de un
vector de hiperparámetros iniciales $\Btheta_0$, entrena en cada
iteración $i$ la máquina de aprendizaje sobre el conjunto $D$ con
hiperparámetros $\Btheta_i$, ajustando sucesivamente el valor de
$\Btheta_{i+1}$ mediante la información disponible del modelo
$h_i$. Este proceso se repite hasta satisfacer algún criterio de
corte.

Más formalmente, un algoritmo de selección automática de
hiperparámetros puede definirse como una transformación
%
\begin{align}
  S:\C{D}\rightarrow\C{P}
\end{align}
%
que, dado un conjunto de entrenamiento ${D}\in\C{D}$, invoca la máquina de
aprendizaje $A$ en sucesivas iteraciones hasta encontrar un vector de
parámetros $\Btheta_*\in\C{P}$ que surge de optimizar una \e{función
  objetivo}, típicamente relacionada al error de generalización del
modelo obtenido en cada iteración.
%
\subsubsection{Función objetivo}
%
Una función objetivo sirve de criterio para determinar la mejor
solución a un problema de optimización, asignando a cada caso de
prueba un valor numérico que refleja la idoneidad del modelo obtenido
con determinados hiperparámetros $\Btheta$.
Intuitivamente, se puede decir que una función objetivo estima el
error de generalización del clasificador, y sus variables de entrada
son, directa o indirectamente, el conjunto de datos de entrenamiento y
los hiperparámetros del clasificador.

Una función objetivo ideal es una función continua, derivable, y con
un mínimo global coincidente con el mínimo de la función del error de
generalización. La función objetivo más utilizada es el error
de clasificación sobre algún conjunto de validación, la cual es una
función discontinua y no derivable, ya que se construye a partir de la
experiencia de clasificación de un conjunto de datos finito.
Sin embargo, como se verá más adelante, resulta posible derivar
funciones objetivo derivables que permiten una solución eficiente al
problema de la búsqueda de hiperparámetros óptimos.
