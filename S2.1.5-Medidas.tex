%
%
\subsection{Regularización}
%
Al minimizar el error de entrenamiento se produce una tendencia al
sobreajuste, lo que se traduce en un rendimiento de generalización
subóptimo. Este sobreajuste genera fronteras de decisión relativamente
complejas para problemas que en realidad tienden a ser más simples.
Esto se condice con un principio a menudo referido como la \e{navaja de
Ockam}:
``las entidades no deben multiplicarse más allá de lo necesario'',
afirmando que las explicaciones simples son más plausibles y los
modelos sencillos son más explicativos y más confiables que los
complicados.

La \e{regularización} consiste en forzar la simplicidad del modelo, y es
una de las estrategias principales utilizadas para evitar el
sobreajuste del modelo generado por la máquina de aprendizaje. Existen
dos formas comunes para incorporar simplicidad en el modelo:
%
\begin{itemize}
\item Limitar el modelo a una subclase de funciones simples.
\item Añadir un término de penalización por complejidad al objetivo
  del error de entrenamiento.
\end{itemize}
%
El segundo enfoque requiere alguna forma de medir la ``complejidad'' del
modelo. Ambos procedimientos regularizan el proceso de aprendizaje, ya
que favorecen las hipótesis más simples.

Cuando el entrenamiento de la máquina de aprendizaje es un proceso
gradual, una técnica alternativa de regularización consiste en
abortar el proceso de entrenamiento al momento que se detecta
que el error de generalización empieza a incrementarse.

Se debe notar que la regularización en general entra en conflicto con
la minimización del error de entrenamiento, y un modelo regularizado
cometerá más errores sobre el conjunto de entrenamiento que un modelo
no regularizado.  Sin embargo, se ha de esperar que el modelo
regularizado tenga mayor capacidad de generalización.
%
%
\subsection{Medidas de evaluación de un clasificador binario}
%
Los clasificadores binarios generan modelos cuya salida toma
exactamente dos valores posibles, que se interpretan en forma genérica
como ``verdadero'' y ``falso''. Para esta clase especialmente
importante de clasificadores se utiliza una serie de métricas que
relacionan la pertenencia de clase de los datos de entrada con el
error de clasificación.

Dado un modelo $h$ con salida binaria, se definen las siguientes
medidas que caracterizan el resultado de clasificar un conjunto de
prueba $T$:
%
\iflatexml\begin{itemize}\else\begin{itemize}[style=nextline]\fi
  \item\e{Verdaderos positivos ($\VP$)}: número de elementos de clase
    positiva correctamente clasificados como positivos.
  \item\e{Verdaderos negativos ($\VN$)}: número de elementos de clase
    negativa correctamente clasificados como negativos.
  \item\e{Falsos positivos ($\FP$)}: número de elementos de clase
    negativa erróneamente clasificados como positivos.
  \item\e{Falsos negativos ($\FN$)}: número de elementos de clase
    positiva erróneamente clasificados como negativos.
\end{itemize}
%
Estas cuatro medidas conforman la llamada \e{matriz de confusión}
característica del clasificador, y dependen en todos los casos del
número de elementos positivos y negativos presentes en el conjunto de
prueba.
