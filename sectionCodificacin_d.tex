\section{Codificación de clasificadores de prueba}
\label{pruebas}

Una vez obtenidas las bases de datos se procedió a codificar
algoritmos de clasificación preliminares.
Se optó por trabajar con el conjunto de datos de \cite{xue},
intentando replicar los resultados obtenidos en ese trabajo mediante
la utilización de herramientas propias. Según se ha observado en la
bibliografía, este trabajo es tomado como modelo de referencia debido a
la simplicidad del método y los buenos resultados que obtiene.

Al analizar el formato de los datos disponibles surge la necesidad
de codificar una herramienta para el manejo de archivos en formato
FASTA\footnote{FASTA es un formato de texto para la representación
  de secuencias de nucleótidos, como es el RNA.
  La especificación se encuentra disponible en
  \url{http://blast.ncbi.nlm.nih.gov/blastcgihelp.shtml}.}.
El formato de salida del programa \mono{RNAFold} es además
muy similar a FASTA, e incorpora la información de la estructura
secuendaria o \emph{plegado} para cada entrada.
Se ha codificado la herramienta \mono{fautil.py} en lenguaje Python,
que permite manipular archivos con formato FASTA/RNAfold. También para
Matlab se ha codificado la utilidad \mono{fastaread.m} para lectura
de estos archivos.

\subsection{Extracción de características}
Tal como en \cite{xue}, se definen 32 elementos ``triplete'', que
relacionan en cada posición la secuencia con la estructura secundaria
en el entorno. Para cada entrada de la base de datos, se calcula la
frecuencia de ocurrencia de cada triplete, generando así un 32-vector
que se utiliza como entrada al clasificador.

El proceso detallado se puede describir como sigue:

\begin{enumerate}
\item A partir de la estructura secundaria, se determina una región a
  considerar para los cálculos, de forma que excluya los extremos
  ``sueltos'' así como el bucle central de la cadena, donde las bases
  no forman pares.
\item Se recorre en esta región tanto la secuencia como la
  estructura secundaria con una ventana de 3nt y paso 1nt. En cada
  paso:
  \begin{enumerate}
  \item Se calcula una cadena de ``elemento triplet'' añadiendo al
    caracter central en la secuencia los tres caracteres
    correspondientes a la estructura secundaria (se ignora la
    orientación en el caso de bases que forman un par). Se obtiene
    así, por ejemplo, el elemento ``\mono{A.((}''.
  \item Se incrementa el contador de ocurrencias para el elemento en
    la posición correspondiente del vector.
  \item En los extremos se ignora un caracter del triplet, que se
    considera en la estructura secundaria como un ``\mono{.}''.
  \end{enumerate}
\itemSe normaliza el vector de frecuencias dividiéndolo por el número
  total de triplets contados.

En el archivo \mono{fautil.py}, rutina \mono{triplet}, se encuentra
una implementación en Python de este proceso. También se ha codificado
el mismo algoritmo en Matlab, \mono{triplet.m}.

\subsection{Clasificadores}
Se generaron 3 clasificadores, según se detallan a continuación.

\begin{enumerate}
\item Clasificador mediante SVM utilizando \emph{libsvm}\cite{libsvm} con los
  parámetros por defecto.
\item Clasificador mediante SVM utilizando el \emph{Bioinformatics
  Toolbox} de Matlab.
\item Clasificador mediante MLP utilizando el \emph{Neural Network
  Toolbox} de Matlab.
\end{enumerate}
La librería \emph{libsvm}\cite{libsvm} provee una utilidad \mono{svm-easy} que
busca en forma automática aquellos parámetros que minimizan el
error. En los otros casos, esta búsqueda se realizó en forma manual,
ajustando los parámetros \mono{boxconstraint} y y \mono{sigma} para
SVM y para MLP ajustando el número de capas ocultas y el número de
nodos por capa oculta.

\subsection{Pruebas}
Los clasificadores se entrenaron con el mismo conjunto de datos de
\cite{xue}, y se probaron con los conjuntos de prueba \emph{Real} (30
elementos), \emph{Pseudo} (1000 elementos) y \emph{Updated} (39
elementos), también de la misma fuente.

En el caso de SVM-Matlab y MLP, se probaron diversos parámetros hasta
encontrar aquellos que obtienen el mejor rendimiento del clasificador.
En la tabla \autoref{testresults} se presentan figuras de rendimiento para
los distintos clasificadores. %En el caso de SVM-Matlab se muestran
En el caso MLP, se encontró que los resultados no varían
significativamente para distintas configuraciones, con diferencias
menores a 3\% en cada caso.  Se muestran entonces para MLP tasas
representativas.