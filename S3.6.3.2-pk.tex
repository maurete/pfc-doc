%
\subsubsection{Estimación de la probabilidad ${p}_k$}
%
La salida del modelo $h$ de una máquina de vectores de soporte
(\iflatexml{}Ecuación~\ref{eq:svm-model-hard}\else\autoref{eq:svm-model-hard}\fi)
puede entenderse como el resultado de aplicar la operación signo sobre
una salida real
%
\begin{align}
\label{e3:svm-model-as-sign-fk}
  c_k \tab= h(\xx_k) = \T{signo}(f_k),\tabs
  f_k\tab=\langle\ww,\BPhi(\xx_k)\rangle+b.
\end{align}
%
Utilizando el método presentado por \citeauthor{platt} en \cite{platt}
se puede calcular un estimador de $p_k$ a partir del valor $f_k$ (la
salida real del modelo antes de aplicar la función signo)
%
\begin{align}
\label{e3:pk-hat}
  \hat{p}_k\tab=\frac{1}{1+e^{Af_k+B}} \tabs \approx p_k.
\end{align}
%
Los parámetros $A$ y $B$ de este ``modelo-$\hat{p}_k$'' se determinan
resolviendo el problema de optimización
%
\begin{align}
  \arg\min_{A,B} \quad & -\sum_{k=1}^{N} \log(E_k)
  \label{abproblem}
\end{align}
%
sobre el conjunto de prueba $T$. La resolución de este
sub-problema se efectúa mediante el algoritmo Rprop \cite{rprop},
aprovechando el hecho que las derivadas de $\hat{p}_k$
respecto de sus parámetros $A$ y $B$ son fácilmente calculables:
%
\begin{align}
  \begin{split}
    \dpar{\hat{p}_k}{A}{}&=-f_k e^{Af_k+B}\frac{1}{(1+e^{Af_k+B})^2}
    =-f_k\hat{p}_k(1-\hat{p}_k),\\
    \dpar{\hat{p}_k}{B}{}&=    -e^{Af_k+B}\frac{1}{(1+e^{Af_k+B})^2}
    =-   \hat{p}_k(1-\hat{p}_k).
  \end{split}
\label{e3:deriv-pk-wrt-AB}
\end{align}
%
La elección de una función logística como $\hat{p}_k$ se basa en la
presunción de que las salidas $f_k$ para las entradas $\{\xx_k\}$ de
clase positiva tienen una distribución gaussiana en $f$.

Una interpretación intuitiva de $\hat{p}_k$ es que, para una salida
$f_k$ de gran magnitud que se ubica lejos del hiperplano de separación
en el espacio inducido por el núcleo, el clasificador SVM tiene amplia
certeza de su decisión.  Asimismo, se tendrá que cuando el valor de
$f_k=0$, $x_k$ recae exactamente en el plano de separación y se
obtiene la peor predicción posible $\hat{p}_k=0.5$\footnote{La
  condición $\hat{p}_k=0.5$ cuando $x_k$ se ubica sobre el plano de
  separación implica $B=0$, sin embargo, se considera igualmente $B$
  como un valor a optimizar, respetando el método original de
  \cite{platt}.} y, similarmente, cuanto más ancho sea el margen de
separación, más suave deberá ser la pendiente de $\hat{p}_k$.
