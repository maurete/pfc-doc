%
%
%
\section{La clasificación como forma de aprendizaje supervisado}
%
En el contexto de la Inteligencia Computacional, la clasificación es
un tipo de \e{aprendizaje supervisado} cuyo objetivo es
{inferir} una función que relaciona \e{datos de entrada} con las
respectivas \e{salidas deseadas}, a partir de una serie de ejemplos que
conforman el llamado \e{conjunto de entrenamiento}. Un algoritmo que
implementa la clasificación se conoce como un \e{clasificador}.
La función que transforma los datos de entrada a una categoría
(clase) se llama \e{modelo} (o {hipótesis}).

Un clasificador es un tipo de \e{máquina de aprendizaje}, y consiste
en un algoritmo que analiza los datos del conjunto de entrenamiento
y produce una función de correspondencia (el modelo) que puede ser
usada para relacionar nuevos ejemplos (datos de entrada) a una clase
(valor de salida).
De este modo, el clasificador es capaz de replicar el comportamiento
del sistema o proceso que pretende modelar, y se dice que el modelo
obtenido es capaz de \e{generalizar} a partir de los datos de
entrenamiento.

A continuación, se presentan definiciones de los conceptos
relevantes del aprendizaje supervisado. La discusión se
basa en el
trabajo de \citeauthor{glasmachers} \cite{glasmachers}.
%
%
\subsection{Conceptos básicos}
%
%
\subsubsection{Aprendizaje supervisado}
%
Sean $X$ e $Y$ espacios vectoriales, y sea $(\xx,\yy)\in{}X\times{}Y$
un \e{ejemplo} (correspondiente a una observación) que relaciona una
entrada $\xx\in{}X$ con la salida correspondiente $\yy\in{}Y$.
%
Se asume que existe una distribución de probabilidades fija y
desconcida $\nu$ sobre el producto $X\times Y$, llamada
\e{distribución generadora} de los datos.  El aprendizaje supervisado
trata la extracción de propiedades de esta distribución a partir de un
número finito de variables aleatorias, denominadas \e{ejemplos}, que
conforman el conjunto de datos de entrenamiento
%
\begin{align}
  D = \left((\B{x}_1,\yy_1),\ldots,(\B{x}_\ell,\yy_\ell)\right) \in
  \mathcal{D}=\bigcup_{\ell=1}^\infty (X\times Y)^\ell,
\end{align}
%
que se considera como una muestra independiente e idénticamente
distribuida de $\nu$, esto es, $D\sim\nu$.
%
\subsubsection{Modelo}
%
En un problema típico de aprendizaje supervisado, se trata de
encontrar una función medible $h:X\rightarrow{}Y$ que {modela} las
propiedades más importantes de la distribución $\nu$. La función $h$
se denomina \e{modelo} o \e{hipótesis}, ya que relaciona el espacio de
entrada $X$ con el de salida $Y$ y representa (con limitaciones) el
fenómeno real que da origen a los datos.
%
\subsubsection{Máquina de aprendizaje}
%
Sea $\C{H}=\{h:X\rightarrow Y\}$ el conjunto de todos los modelos
posibles. Una máquina de aprendizaje es una transformación
%
\begin{align}
  A:\mathcal{D}\rightarrow\C{H}
  \label{eq:maqaprendizaje}
\end{align}
%
que relaciona un conjunto de datos a un modelo.
La máquina de aprendizaje $A$ no necesariamente es una transformación
en el sentido matemático, sino que en general se trata de un algoritmo
que efectúa el proceso denominado \e{entrenamiento}.
%
\subsubsection{Clasificador}
%
Se dice que se está ante un problema de \e{clasificación} cuando el
espacio de las salidas $Y$ es un conjunto discreto y finito, donde
cada valor posible de $Y$ se corresponde con una categoría o
\emph{clase}. El caso más básico e importante es el de la
\e{clasificación binaria}, en la que se consideran sólo dos valores en
$Y$, comúnmente $+1$ y $-1$.

Un \e{clasificador} es, entonces, el caso especial de una máquina de
aprendizaje cuando el espacio de salida $Y$ es discreto y finito.
Naturalmente, siempre que se hable de máquinas de aprendizaje se
incluyen los clasificadores dentro de esta denominación.
%
\subsubsection{Función de pérdida}
%
Para un ejemplo $(\xx,\yy)\in{}X\times{}Y$, la función de pérdida mide
la cantidad de error del modelo $\hat{\yy}=h(\xx)$ mediante la
transformación $L(\xx,\yy,\hat{\yy})$.  Si la predicción resultante
del modelo $\hat{\yy}$ es correcta, el error es nulo. En la práctica,
la mayoría de las funciones de pérdida no dependen de la entrada
$\xx$, sino sólo de la predicción $\hat{\yy}$ y la clase $\yy$.
Algunas de las funciones de pérdida más comunes son:
%
\begin{align}
  \T{Pérdida 0-1:} \tab\tabs
    L(\yy,\hat{\yy})=\begin{cases}0,\quad{}\yy=\hat{\yy}\\
      1,\quad\T{en otro caso}\end{cases} \\
  \T{Pérdida ``bisagra'':} \tab\tabs
    L(\yy,\hat{\yy})=\max\{0,\yy-\hat{\yy}\}\\
  \T{Error absoluto:} \tab\tabs
    L(\yy,\hat{\yy})=|\yy-\hat{\yy}|\\
  \T{Error cuadrático:} \tab\tabs
    L(\yy,\hat{\yy})=(\yy-\hat{\yy})^2.
\end{align}
%
\subsubsection{Error de generalización}
%
El error de generalización
$\mathcal{R}_\nu:\C{H}\rightarrow\RR^{\geq0}$ es el error esperado de
un modelo $h$ al clasificar un ``nuevo'' ejemplo independiente
del conjunto $D$, y se define a partir de la función de pérdida $L$ según
%
\begin{align}
  \mathcal{R}_\nu=\mathds{E}_\nu\left[L(x,y,h(x))\right]
  =\int_{X\times Y} L(x,y,h(x))\, d\nu(x,y).
\end{align}
%
El cálculo de este error requiere conocer la distribución generadora
de datos $\nu$. Sin embargo, toda la información que se tiene de $\nu$
es la realización $D$, para la cual no se conoce su probabilidad.
Por ello, la aplicación del concepto de error de generalización es
teórica, utilizando en la práctica medidas que lo aproximan.
%
%
\subsection{Entrenamiento}
%
Todo el conocimiento que se tiene sobre la distribución generadora de
datos $\nu$ proviene del conjunto de datos finito
$D=\left((x_1,y_1),\ldots,(x_\ell,y_\ell)\right)$.  Este conjunto de
datos define una distribución empírica
%
\begin{align}
  \hat{\nu}=\frac{1}{\ell}\sum_{i=1}^{\ell}\delta_{(x_i,y_i)}(x,y)
\end{align}
%
donde $\delta_{(x,y)}$ denota el delta de Dirac en
$(x,y)\in{}X\times{}Y$.  Esta distribución conduce a la definición del
\e{error de entrenamiento} como el error de un modelo $h$ sobre los
datos de entrenamiento en $D$:
%
\begin{align}
  \hat{\C{R}}_D(h)=E_\T{entrenamiento}=\R{E}_{\hat{\nu}}[L(x,y,h(x))]
  =\frac{1}{\ell}\sum_{i=1}^\ell L(x_i, y_i, h(x_i)),
\end{align}
%
en donde $L$ es una función de pérdida.

El entrenamiento de la máquina de aprendizaje consiste en
seleccionar el modelo con el mínimo error de entrenamiento
%
\begin{align}
  \hat{h}:=\arg \min \left\{ \hat{\C{R}}_D(h)\middle|h \in H\right\}.
\end{align}
%
Este procedimiento se conoce también como la minimización del riesgo
empírico, y define una máquina de aprendizaje
$A_H:\C{D}\rightarrow{}H$ para cada clase $H$ de modelo.
%
\subsubsection{Sobreajuste}
%
Se dice que un modelo presenta \e{sobreajuste} cuando éste describe
el conjunto de datos de entrenamiento en lugar de la relación
subyacente $\nu$ entre las variables de entrada y de salida.
Intuitivamente, se puede decir que existe sobreajuste cuando el modelo
\e{memoriza ejemplos} del conjunto de aprendizaje en lugar de
\e{aprender las propiedades} de la relación que existe entre las variables
de entrada y de salida. El problema del
sobreajuste existe debido a que la máquina de aprendizaje no recibe
información acerca de la \e{probabilidad} de cada ejemplo observado,
ignorando el ruido y los efectos aleatorios en el conjunto de datos de
entrenamiento.
