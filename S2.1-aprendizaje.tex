%
%
%
\section{La clasificación como forma de aprendizaje supervisado}
%
En el contexto de la Inteligencia Computacional, la clasificación es
un tipo de \e{aprendizaje supervisado} cuyo objetivo es
\e{inferir} una función que relaciona \e{datos de entrada} con las
respectivas \e{salidas deseadas} a partir de una serie de ejemplos que
conforman el llamado \e{conjunto de entrenamiento}.  Un algoritmo que
implementa la clasificación se conoce como un \e{clasificador}.
La función que transforma los datos de entrada a una categoría
(clase) se llama \e{modelo} (o \e{hipótesis}).

Un clasificador es un tipo de \e{máquina de aprendizaje}, y consiste
en un algoritmo que analiza los datos del conjunto de entrenamiento
y produce una función de correspondencia (el modelo) que puede ser
usada para relacionar nuevos ejemplos (datos de entrada) a una clase
(valor de salida).
De este modo, el clasificador es capaz de replicar el comportamiento
del sistema o proceso que pretende modelar, y se dice que el modelo
obtenido es capaz de \e{generalizar} a partir de los datos de
entrenamiento.
%
%
\subsection{Conceptos básicos}
%
A continuación se presenta una introducción a aquellos conceptos
básicos de la disciplina del aprendizaje supervisado, basada en el
trabajo de \citeauthor{glasmachers} \cite{glasmachers}.
%
\subsubsection{Aprendizaje supervisado}
%
Una definición formal del concepto de aprendizaje supervisado
puede expresarse como a continuación.

Sean $X$ e $Y$ espacios vectoriales, y sea $(\xx,\yy)\in{}X\times{}Y$
un \e{ejemplo} (correspondiente a una observación) que relaciona una
entrada $\xx\in{}X$ con la salida correspondiente $\yy\in{}Y$.
%
Se asume que existe una distribución de probabilidades fija y
desconcida $\nu$ sobre el producto $X\times Y$, llamada
\e{distribución generadora} de los datos.  El aprendizaje supervisado
trata la extracción de propiedades de esta distribución a partir de un
número finito de variables aleatorias, denominadas \e{ejemplos}, que
conforman el conjunto de datos de entrenamiento
%
\begin{align}
  D = \left((\B{x}_1,\yy_1),\ldots,(\B{x}_\ell,\yy_\ell)\right) \in
  \mathcal{D}=\bigcup_{\ell=1}^\infty (X\times Y)^\ell,
\end{align}
%
que se considera como una muestra independiente e idénticamente
distribuida de $\nu$, esto es, $D\sim\nu$.
%
\subsubsection{Modelo}
%
En un problema típico de aprendizaje supervisado, se trata de
encontrar una función medible $h:X\rightarrow{}Y$ que {modela} las
propiedades más importantes de la distribución $\nu$. La función $h$
se denomina \e{modelo} o \e{hipótesis}, ya que relaciona el espacio de
entrada $X$ con el de salida $Y$ y representa (con limitaciones) el
fenómeno real que da origen a los datos.
%
\subsubsection{Máquina de aprendizaje}
%
Sea $\C{H}=\{h:X\rightarrow Y\}$ el conjunto de todos los modelos
posibles. Una máquina de aprendizaje es una transformación
%
\begin{align}
  A:\mathcal{D}\rightarrow\C{H}
  \label{eq:maqaprendizaje}
\end{align}
%
que relaciona un conjunto de datos a un modelo.
La máquina de aprendizaje $A$ no necesariamente es una transformación
en el sentido matemático, sino que en general se trata de un algoritmo
que efectúa el proceso denominado \e{entrenamiento}.
%
\subsubsection{Clasificador}
%
Se dice que se está ante un problema de \e{clasificación} cuando el
espacio de las salidas $Y$ es un conjunto discreto y finito, donde
cada valor posible de $Y$ se corresponde con una categoría o
\emph{clase}. El caso más básico e importante es el de la
\e{clasificación binaria}, en la que se consideran sólo dos valores en
$Y$, comúnmente $+1$ y $-1$.

Un \e{clasificador} es, entonces, el caso especial de una máquina de
aprendizaje cuando el espacio de salida $Y$ es discreto y finito.
Naturalmente, siempre que se hable de máquinas de aprendizaje se
incluyen los clasificadores dentro de esta denominación.
%
\subsubsection{Función de pérdida}
%
Para un ejemplo $(\xx,\yy)\in{}X\times{}Y$, la función de pérdida mide
la cantidad de error del modelo $\hat{\yy}=h(\xx)$ mediante la
transformación $L(\xx,\yy,\hat{\yy})$.  Si la predicción resultante
del modelo $\hat{\yy}$ es correcta, el error es nulo. En la práctica,
la mayoría de las funciones de pérdida no dependen de la entrada
$\xx$, sino sólo de la predicción $\hat{\yy}$ y la clase $\yy$.
Algunas de las funciones de pérdida más comunes son:
%
\begin{align}
  \T{Pérdida 0-1:} \tab\tabs
    L(\yy,\hat{\yy})=\begin{cases}0,\quad{}\yy=\hat{\yy}\\
      1,\quad\T{en otro caso}\end{cases} \\
  \T{Pérdida ``bisagra'':} \tab\tabs
    L(\yy,\hat{\yy})=\max\{0,\yy-\hat{\yy}\}\\
  \T{Error absoluto:} \tab\tabs
    L(\yy,\hat{\yy})=|\yy-\hat{\yy}|\\
  \T{Error cuadrático:} \tab\tabs
    L(\yy,\hat{\yy})=(\yy-\hat{\yy})^2.
\end{align}
%
\subsubsection{Error de generalización}
%
El error de generalización
$\mathcal{R}_\nu:\C{H}\rightarrow\RR^{\geq0}$ es el error esperado de
un modelo $h$ al clasificar un ``nuevo'' ejemplo independiente
del conjunto $D$, y se define a partir de la función de pérdida $L$ según
%
\begin{align}
  \mathcal{R}_\nu=\mathds{E}_\nu\left[L(x,y,h(x))\right]
  =\int_{X\times Y} L(x,y,h(x))\, d\nu(x,y).
\end{align}
%
El cálculo de este error requiere conocer la distribución generadora
de datos $\nu$. Sin embargo, toda la información que se tiene de $\nu$
es la realización $D$, para la cual no se conoce su probabilidad.
Por ello, la aplicación del concepto de error de generalización es
teórica, utilizando en la práctica medidas que lo aproximan.
%
%
\subsection{Entrenamiento}
%
Todo el conocimiento que se tiene sobre la distribución generadora de
datos $\nu$ proviene del conjunto de datos finito
$D=\left((x_1,y_1),\ldots,(x_\ell,y_\ell)\right)$.  Este conjunto de
datos define una distribución empírica
%
\begin{align}
  \hat{\nu}=\frac{1}{\ell}\sum_{i=1}^{\ell}\delta_{(x_i,y_i)}(x,y)
\end{align}
%
donde $\delta_{(x,y)}$ denota el delta de Dirac en
$(x,y)\in{}X\times{}Y$.  Esta distribución conduce a la definición del
\e{error de entrenamiento} como el error de un modelo $h$ sobre los
datos de entrenamiento en $D$:
%
\begin{align}
  \hat{\C{R}}_D(h)=E_\T{entrenamiento}=\R{E}_{\hat{\nu}}[L(x,y,h(x))]
  =\frac{1}{\ell}\sum_{i=1}^\ell L(x_i, y_i, h(x_i)),
\end{align}
%
en donde $L$ es una función de pérdida.

El entrenamiento de la máquina de aprendizaje consiste en
seleccionar el modelo con el mínimo error de entrenamiento
%
\begin{align}
  \hat{h}:=\arg \min \left\{ \hat{\C{R}}_D(h)\middle|h \in H\right\}.
\end{align}
%
Este procedimiento se conoce también como la minimización del riesgo
empírico, y define una máquina de aprendizaje
$A_H:\C{D}\rightarrow{}H$ para cada clase $H$ de modelo.
%
\subsubsection{Sobreajuste}
%
Se dice que un modelo presenta \e{sobreajuste} cuando éste describe
el conjunto de datos de entrenamiento en lugar de la relación
subyacente $\nu$ entre las variables de entrada y de salida.
Intuitivamente, se puede decir que existe sobreajuste cuando el modelo
\e{memoriza ejemplos} del conjunto de aprendizaje en lugar de
\e{aprender las propiedades} de la relación que existe entre las variables
de entrada y de salida. El problema del
sobreajuste existe debido a que la máquina de aprendizaje no recibe
información acerca de la \e{probabilidad} de cada ejemplo observado,
ignorando el ruido y los efectos aleatorios en el conjunto de datos de
entrenamiento.
%
%
\subsection{Estimación del error de generalización}
%
El error de generalización es la medida más acertada para evaluar la
aptitud de un modelo al clasificar datos nuevos.  Sin embargo, al
tratarse de un valor no calculable, se hace necesario estimarlo
mediante medidas de error alternativas.
%
\subsubsection{Error de prueba}
%
Una situación óptima se da cuando se dispone de una muestra $T$,
independiente e idénticamente distribuida a $\nu$, denominada
\e{conjunto de prueba}:
%
\begin{align}
  T=((\tilde{x}_1,\tilde{y}_1),\ldots,(\tilde{x}_N,\tilde{y}_N))\sim\nu^N.
  \label{eq:conj-prueba}
\end{align}
%
A partir del conjunto $T$ se define el \e{error de prueba}
(o \e{de test}) como la pérdida media
%
\begin{align}
  E_{test}=\frac{1}{N}\sum_{n=1}^N
  L(\tilde{x}_N,\tilde{y}_N,h(\tilde{x}_N)).
  \label{eq:error-prueba}
\end{align}
%
Este error de prueba es una estimación no sesgada del error de
generalización verdadero $\C{R}_\nu(h)$, y puede ser utilzado para
comparar modelos.
%
\subsubsection{Método de retención}
\label{retencion}
%
Con frecuencia, en los problemas reales el conjunto de prueba $T$ no
viene dado como tal, y en cambio se genera un conjunto $T^*\subset{}D$
seleccionando ejemplos al azar del conjunto de entrenamiento $D$.  A
fin de que exista una cierta ``independencia''\footnote{Estrictamente,
  la independencia no existe en este caso, ya que la pertenencia de un
  ejemplo al conjunto de entrenamiento $D^*$ implica la no pertenecia
  al conjunto de prueba $T^*$.} de los datos en $T^*$ respecto del
conjunto de entrenamiento, se genera un nuevo conjunto de entrenamiento
$D^*\subset{}D:D^*\cap{}T^*=\emptyset$ que será usado para entrenar la
máquina de aprendizaje. El conjunto $D^*$ se denomina en ocasiones
\e{conjunto de estimación}.
Finalmente, el error de prueba puede ser estimado calculando el error
sobre el conjunto $T^*$. Este método es conocido como el \e{método de
  retención}.
%
\subsubsection{Validación cruzada de $k$ iteraciones}
%
En un procedimiento de \emph{validación cruzada de $k$ iteraciones}
\cite{crossval}, el conjunto $D$ se subdivide en $k$ conjuntos
disjuntos $D_1,\ldots,D_k$ de tamaños similares denominados
\e{particiones}.

El entrenamiento de la máquina de aprendizaje se efectúa sobre $k-1$
particiones, y se clasifican aquellos datos de la partición restante
(llamada \e{de validación}) para obtener una medida de desempeño de
clasificación de la partición actual. Se repite el procedimiento $k$
veces, seleccionando en cada iteración una partición diferente para
validación.  Una vez completado el proceso, se dispondrá de $k$
medidas de desempeño de la máquina de aprendizaje. Estas medidas
pueden ser promediadas para obtener un estimador del desempeño de la
máquina de aprendizaje. Este estimador es una medida más acertada que
el error de entrenamiento para estimar el error de generalización del
modelo.

El error de validación cruzada presenta una menor varianza que aquel
del método de retención, sin embargo, al no ser los subconjuntos $D_i$
independientes e idénticamente distribuidos entre sí, se introduce un
sesgo en la estimación del error de generalización.  Tal como en el
caso del método de retención, en conjuntos de datos pequeños el método
de validación cruzada presenta una alta varianza respecto de la
elección de diferentes $D_i$.
%
\subsubsection{Validación cruzada dejando uno fuera}
%
En el método de validación cruzada ``clásico'' de $k$ iteraciones, se
tiene para valores pequeños de $k$ una reducción en la varianza y para
valores grandes una reducción del sesgo introducido por el particionado.
En el extremo, cuando se
establece $k$ al número de elementos en $D$, se está ante un método de
\e{validación cruzada dejando uno fuera}. La condición $k=\ell=\|D\|$
implica la reducción del sesgo a un valor mínimo, ya que se separa
sólo un elemento para validación. Sin embargo, la varianza obtenida
mediante este método es máxima.

Para obtener una estimación del error de generalización mediante este
método es necesario entrenar el clasificador $\ell$ veces, lo que deriva
en un costo computacional muy elevado. Sin embargo, para el caso de un
clasificador SVM existen técnicas para el cálculo eficiente del error
dejando uno fuera \cite{chapelle,lee-keerthi}.
%
%
\subsection{Regularización}
%
Al minimizar el error de entrenamiento se produce una tendencia al
sobreajuste, lo que se traduce en un rendimiento de generalización
subóptimo. Este sobreajuste genera fronteras de decisión relativamente
complejas para problemas que en realidad tienden a ser más simples.
Esto se condice con un principio a menudo referido como la \e{navaja de
Ockam}:
``las entidades no deben multiplicarse más allá de lo necesario'',
afirmando que las explicaciones simples son más plausibles y los
modelos sencillos son más explicativos y más confiables que los
complicados.

La \e{regularización} consiste en forzar la simplicidad del modelo, y es
una de las estrategias principales utilizadas para evitar el
sobreajuste del modelo generado por la máquina de aprendizaje. Existen
dos formas comunes para incorporar simplicidad en el modelo:
%
\begin{itemize}
\item Limitar el modelo a una subclase de funciones simples.
\item Añadir un término de penalización por complejidad al objetivo
  del error de entrenamiento.
\end{itemize}
%
El segundo enfoque requiere alguna forma de medir la ``complejidad'' del
modelo. Ambos procedimientos regularizan el proceso de aprendizaje, ya
que favorecen las hipótesis más simples.

Cuando el entrenamiento de la máquina de aprendizaje es un proceso
gradual, una técnica alternativa de regularización consiste en
abortar el proceso de entrenamiento al momento que se detecta
que el error de generalización empieza a incrementarse.

Se debe notar que la regularización en general entra en conflicto con
la minimización del error de entrenamiento, y un modelo regularizado
cometerá más errores sobre el conjunto de entrenamiento que un modelo
no regularizado.  Sin embargo, se ha de esperar que el modelo
regularizado tenga mayor capacidad de generalización.
