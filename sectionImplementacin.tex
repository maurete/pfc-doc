\section{Implementación}
La implementación se realizó en todos los casos en lenguaje
\eng{Matlab}, y el código fuente se encuentra disponible en
\url{https://github.com/maurete/pfc}. Se implementaron métodos de
entrenamiento, clasificación y selección de parámetros, así como
métodos auxiliares para carga de datos, validación cruzada, cálculo de
gradiente y optimización.

Los métodos de selección de parámetros codificados
reciben como argumento una estructura en memoria que describe el
problema a tratar, y retornan en un vector numérico los parámetros
óptimos encontrados para el clasificador especificado.

\subsection{MLP}
Para el clasificador MLP se utilizó las implementación del paquete
\eng{Neural Network Toolbox} de Matlab. Se codificó además el soporte
para la biblioteca de código libre
\eng{FANN}\footnote{\url{http://leenissen.dk/fann/wp/}}, aunque
durante pruebas iniciales se decidió descartar su utilización por
problemas de desempeño.  El criterio de corte de entrenamiento del
clasificador se estableció como la época en la que se obtiene la menor
tasa de error sobre el conjunto de validación.  Se fijó el número de
capas ocultas a 1, y como método de propagación hacia atrás se utilizó
Rprop \cite{rprop}, que en pruebas preliminares resultó ser
el más rápido de los métodos disponibles.

Se codificó un método de selección de parámetros que determina el
número de neuronas en la capa oculta mediante búsqueda exhaustiva,
probando entre 0 neuronas (caso especial de un perceptrón simple) y
la longitud del vector de entrada.

\subsection{SVM}
En el caso SVM se utilizaron las implementaciones disponibles tanto en
el \eng{Bioinformatics Toolbox} del software Matlab como en la
biblioteca \eng{libSVM} \cite{chang}, con funciones de kernel lineal y
RBF.  Se implementaron para la selección de parámetros los métodos de
búsqueda en la grilla, de error empírico, RMB y trivial.

Para el método de búsqueda en la grilla se estableció un muestreo
inicial de los parámetros $C=2^{-5},2^{-3},\ldots,2^{15}$ y, cuando se
utiliza kernel RBF, $\gamma={2^{-15},2^{-13},\ldots,2^3}$ \cite{hsu}.
Se estableció como criterio de evaluación del clasificador la medida
$G_m$, siguiendo el ejemplo de la bibliografía \cite{xue,batuwita}.
Se codificaron tres estrategias de refinamiento de la grilla,
denominadas \eng{threshold}, \eng{zoom} y \eng{nbest}, y mediante
pruebas se determinó la utilización por defecto la estrategia
\eng{threshold}, refinando la grilla en tres iteraciones sucesivas.

Para los métodos de error empírico y RMB se implementaron métodos de
cálculo de gradiente a partir de las salidas del clasificador, junto
con los métodos de optimización requeridos BFGS \cite{nocedal} y
\eng{line search} \cite{linesearch}.
La implementación realizada del método RMB requiere que la biblioteca
\eng{libSVM} se encuentre disponible, ya que utiliza sus funciones para
un cálculo intermedio, independientemente del hecho que se utilice o no
la biblioteca para el clasificador SVM.

\chapter{Proyecto}