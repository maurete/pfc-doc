%
%
\subsection{Minimización de la cota radio-margen}
%
Una cota ``radio-margen'' es una función de derivación teórica que
sirve como límite superior al error de clasificación
\e{dejando-uno-fuera} del modelo SVM sobre el conjunto de
entrenamiento.
La primera función de este tipo fue propuesta en \cite{vapnik}
para modelos SVM con regularización $L2$ y viene dada por
% vapnik sec. 10.7, pag 441
\begin{align}
  \T{RM} = 4R^2 \|\ww\|^2.
\end{align}
%
Aquí, $R$ es el radio de la hiperesfera que contiene todos los
vectores de soporte en el espacio inducido $Z$ y $\ww$ es el vector
normal al hiperplano de separación del modelo.
Puede mostrarse que la función RM cumple la propiedad
%
\begin{align}
  E_{\T{LOO}} \leq \T{RM},
\end{align}
%
donde $E_{\T{LOO}}$ es el error de validación cruzada dejando uno
fuera.
Esta propiedad, junto al hecho de ser derivable respecto de los
\hparam{s}, convierte a RM en una función objetivo idónea en un
esquema de minimización mediante descenso por gradiente.
En \cite{chapelle} se presenta un método para selección automática de
hiperparámetros basado en esta función.
Sin embargo, su utilidad práctica es limitada, ya que
la SVM con regularización $L2$ no es muy utilizada.

En \cite{chung} se proponen formulaciones alternativas a RM,
aplicables a una formulación SVM con regularización $L1$ y núcleo
gaussiano (RBF).
En particular, se considera la función
%
\begin{align}
  \rho = \rho_R \cdot \rho_M,
\end{align}
%
donde $\rho_R$ y $\rho_M$ son, respectivamente, los factores ``radio''
y ``margen''
%
\begin{align}
  \rho_R &= R^2+\frac{1}{C}, \\
  \rho_M &= \|\ww\|^2+2C\sum\xi_i.
\end{align}
%
A diferencia de {RM}, la función $\rho$ ajusta el error $E_{\T{LOO}}$
con demasiada holgura, por lo que pierde el significado original de
representar una tasa de error.
Sin embargo, mantiene la propiedad de poseer un mínimo global cerca
del punto que minimiza la tasa de error $E_{\T{LOO}}$.
