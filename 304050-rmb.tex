%
%
\subsection{Minimización de la cota radio-margen ${\rho}$}
%
Esta estrategia se basa en el método propuesto en \cite{chung}, y
trata de encontrar los \hparam{s} óptimos para un clasificador SVM con
núcleo gaussiano, minimizando una función llamada ``cota
radio-margen'' que en adelante se denota con el símbolo $\rho$.

La función $\rho$ es una adaptación heurística para los clasificadores
SVM con regularización $L1$ de otra función {RM}, propuesta
originalmente en \cite{vapnik} para máquinas de vectores de soporte
con regularización $L2$.
La función {RM} relaciona el radio de la hiperesfera que contiene a
los vectores de soporte con la amplitud del margen del modelo, y
cumple con la siguiente propiedad:
%
\begin{align}
  E_{\T{LOO}} \leq \T{RM}.
\end{align}
%
Aquí, $E_{\T{LOO}}$ representa el error de validación cruzada
dejando-uno-fuera, luego la función {RM} funciona como una cota
superior de este error.
%% % vapnik sec. 10.7, pag 441
%% \begin{align}
%%   \T{RM} = 4R^2 \|\ww\|^2.
%% \end{align}
%% %
Esta propiedad hace que {RM} sea atractiva como función objetivo de
optimización, ya que minimizar {RM} implica minimizar también el error
$E_{\T{LOO}}$ del modelo.
%% De hecho, en \cite{chapelle} se presenta un método para selección
%% automática de hiperparámetros basado en esta función.

La función $\rho$ es una versión modificada de {RM}, que si bien no
representa estrictamente una cota, ya que ajusta el error
$E_{\T{LOO}}$ con demasiada holgura, posee un mínimo global cerca del
punto que minimiza la tasa de error $E_{\T{LOO}}$.

En adelante, se describe la función $\rho$ y su método de cálculo, la
derivación del gradiente respecto a los \hparam{s} y el algoritmo de
minimización utilizados en esta estrategia.
