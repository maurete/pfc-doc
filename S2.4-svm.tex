%
%
%
\section{Máquina de vectores de soporte}
%
La máquina de vectores de soporte (\eng{Support Vector Machine, SVM})
es una máquina de aprendizaje propuesta por Boser et al. \cite{boser}
y Cortes y Vapnik \cite{svm}, basada en el clasificador lineal.
Debido a la simplicidad de su formulación y al cálculo eficiente de su
solución, se ha convertido en una técnica muy popular para
clasificación.

En una máquina de vectores de soporte, se consideran los ejemplos
$(\xx_i,y_i)$ como vectores en el espacio vectorial $X$
``etiquetados'' según su clase $y_i$.  En primer lugar, la SVM aplica
una transformación de las entradas convirtiéndolas en vectores
etiquetados $(\zz_i,y_i)$ en un espacio vectorial ``imagen'' $Z$.  El
espacio $Z$ se encuentra dividido en 2 regiones delimitadas por un
hiperplano de separación. Al clasificar, la clase $\hat{y}_i$ del
vector $\zz_i$ se determina según éste se ubique a un lado u otro del
hiperplano de separación.  El entrenamiento de la máquina de vectores
de soporte consiste en encontrar el hiperplano de separación óptimo,
que maximice la distancia a los vectores de entrenamiento
(transformados) $\zz_i$ más cercanos.

La popularidad de la máquinas de vectores de soporte se debe en gran
parte a que los cálculos en el espacio $Z$ se efectúan de manera
implícita, ahorrando el costo computacional de efectuar la
transformación $\BPhi:X\rightarrow{}Z$ de forma explícita. Esto se
logra mediante la utilización de familias especiales de funciones
denominadas núcleos.

En su variante más común, la máquina de vectores de soporte incorpora
adicionalmente un término de regularización que permite su aplicación
a conjuntos de datos no separables, al mismo tiempo que permite
reducir la complejidad de la solución, evitando el sobreajuste.

A continuación se presenta una descripción de las máquinas de
vectores de soporte según un criterio de ``complejidad'' de su
formulación: partiendo de la descripción de un clasificador lineal
clásico, se formula la búsqueda del hiperplano de separación óptimo
como un problema de optimización.  Luego, se plantea este problema en
una forma alternativa, denominada \e{dual}, que da lugar a la
introducción del concepto de \e{núcleo}. Con estos conceptos se define
la máquina de vectores de soporte de \e{margen duro}, apta para
clasificar conjuntos de datos separables. Finalmente, se introduce un
término de regularización en el problema de optimización, que da lugar
a la forma más general de la SVM, llamada de \e{margen blando}.
