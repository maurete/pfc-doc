%
\subsubsection{Ajuste de los pesos $\ww_{ij}$ en el entrenamiento en línea}
%
En cada paso $t$ se calcula la respuesta de la red $\B{s}(t)$ para la
entrada $\xx(t)$ y luego se calcula el gradiente
$\dpar{\C{E}(t)}{w_{ij}}{}$ propagando hacia atrás la señal de error
$\C{E}(t)$.
A partir de la información del gradiente se aplica una corrección
$\Delta{}w_{ij}(t)$ sobre el peso $w_{ij}(t)$, según la ``regla
delta''
%
\begin{align}
\label{e2:delta-rule}
  \Delta w_{ij}(t)\tab=-\eta\dpar{\C{E}(t)}{w_{ij}}{},
\end{align}
%
en donde $\eta$ es el parámetro \e{velocidad de aprendizaje} del
algoritmo de retropropagación.
La utilización del signo menos indica el \e{descenso por gradiente} en
el espacio de los pesos $w_{ij}$.
Esto implica que el ajuste efectuado modifica los pesos en la
dirección que reduce el valor de $\C{E}(t)$.
El entrenamiento en línea funciona bien cuando se requiere una
adaptación continua de la red, o cuando el conjunto de entrenamiento
es muy grande y/o contiene información redundante.
