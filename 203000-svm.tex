%
%
%
\section{Máquina de vectores de soporte}
%
La \MVS{} (\eng{Support Vector Machine, SVM})
es una máquina de aprendizaje propuesta por Boser et al. \cite{boser}
y Cortes y Vapnik \cite{svm} que puede ser utilizada para tareas de
clasificación y regresión.
Su funcionamiento se basa en la construcción de un modelo en el cual
los ejemplos son representados como puntos en el espacio.
En un problema de clasificación, el entrenamiento de la SVM construye,
a partir de los ejemplos en el conjunto de entrenamiento, una frontera
de decisión que permite determinar la pertenencia de clase de los
ejemplos según se ubiquen a un lado u otro de la frontera.
La popularidad de las \MVS{s} se debe en gran
parte a que permiten incorporar no-linealidad a la representación
vectorial de los ejemplos de manera eficiente, mediante la utilización
de familias especiales de funciones denominadas \e{núcleos}.

La \MVS{} es un tipo de \e{clasificador
  lineal} que incorpora tres propiedades importantes:
%
\begin{enumerate}
\item El algoritmo de entrenamiento genera una frontera de decisión
  óptima desde el punto de vista geométrico.
\item Efectúa los cálculos entre los vectores (ejemplos) de manera
  eficiente mediante la utilización de funciones especiales
  denominadas \e{núcleos}.
\item Incorpora regularización al modelo, lo que evita el sobreajuste
  y al mismo tiempo permite aplicar el clasificador a datos no
  separables.
\end{enumerate}
%
A continuación se presenta una descripción de la SVM comenzando por el
clasificador lineal e incorporando estas propiedades hasta alcanzar la
formulación más general, que utiliza funciones núcleo e incorpora
regularización al modelo.
En esta descripción se trata la obtención del modelo de un
clasificador binario a partir de un conjunto de entrenamiento en donde
el indicador de clase de cada ejemplo toma alguno de los dos valores
posibles $y_i=+1$ o $y_i=-1$.
