%
%
\subsection{El algoritmo de retropropagación}
%
El algoritmo de retropropagación es un algoritmo específico para el
perceptrón multicapa que efectúa entrenamiento ajustando los pesos
$w_{ij}$ de la red en el sentido que minimiza la función de error
$\C{E}$, a partir de la información obtenida del gradiente
$\nabla\C{E}=\dpar{\C{E}}{w_{ij}}{}$.

%% Aprovechando la arquitectura del MLP, el algoritmo de retropropagación
%% calcula el gradiente de la función de error comenzando por la capa de
%% salida y \e{propagando} el error $E$ en dirección inversa hasta la
%% primer capa oculta.

La idea básica del algoritmo de retropropagación es aplicar a cada
peso sináptico $w_{ij}(n)$ de la red una corrección
$\Delta{}w_{ij}(n)$ proporcional a la derivada parcial
$\dpar{\C{E}(n)}{w_{ij}}{}$. Según la regla de la cadena, esta derivada parcial puede escribirse
%
\begin{align}\label{e2:deriv-E-wrt-w-expanded}
  \dpar{\C{E}(n)}{w_{ij}}{} = \dpar{\C{E}(n)}{e_i}{}
  \dpar{e_i(n)}{s_i(n)}{}\dpar{s_i(n)}{v_i(n)}{}
  \dpar{v_i(n)}{w_{ij}}{}.
\end{align}
%
Diferenciando ambos lados de la 
\iflatexml{}Ecuación~\ref{e2:error-energy-net}\else\autoref{e2:error-energy-net}\fi 
respecto de $e_i(n)$, se tiene
%
\begin{align}\label{e2:deriv-E-wrt-e}
  \dpar{\C{E}(n)}{e_i(n)}{} = e_i(n).
\end{align}
%
Por la  
\iflatexml{}Ecuación~\ref{e2:error-signal-neuron}\else\autoref{e2:error-signal-neuron}\fi,
la derivada de $e_i(n)$ respecto de $s_i(n)$ viene dada por
%
\begin{align}\label{e2:deriv-e-wrt-s}
  \dpar{e_i(n)}{s_i(n)}{} = -1.
\end{align}
%
Por la
\iflatexml{}Ecuación~\ref{e2:neuron-general}\else\autoref{e2:neuron-general}\fi,
se tiene
%
\begin{align}\label{e2:deriv-s-wrt-v}
  \dpar{s_i(n)}{v_i(n)}{} \tab = f'(v_i(n)),\\
  \dpar{v_i(n)}{w_{ij}(n)}{} \tab = s_j(n).\\
\end{align}
%
Reemplazando las Ecuaciones \ref{e2:deriv-E-wrt-e}--\ref{e2:deriv-s-wrt-v} en
la
\iflatexml{}Ecuación~\ref{e2:deriv-E-wrt-w-expanded}\else\autoref{e2:deriv-E-wrt-w-expanded}\fi,
se tiene
%
\begin{align}\label{e2:deriv-E-wrt-w}
  \dpar{\C{E}(n)}{w_{ij}}{} = -e_i(n) f'(v_i(n)) s_j(n).
\end{align}
%

%% %
%% \begin{align}\label{e2:deriv-E-wrt-w}
%%   \dpar{E}{w_{ij}}{} = \dpar{E}{s_{i}}{}\dpar{s_i}{w_{ij}}{},
%% \end{align}
%% %
%% donde
%% %
%% \begin{align}\label{e2:deriv-s-wrt-w}
%%   \dpar{s_i}{w_{ij}}{} = \dpar{s_i}{v_{i}}{}\dpar{v_i}{w_{ij}}{} =
%%   f'(v_i) s_j .
%% \end{align}
%% %

El cálculo de $\dpar{E}{s_i}{}$, que representa la influencia
de la salida $s_i$ de la unidad $i$ en el error global $E$,
se distinguen los casos siguientes:
%
\begin{itemize}
\item Si la neurona $i$ está en la capa de salida:
  %
  \begin{align}\label{e2:deriv-E-wrt-s-out} %mlp4
    \dpar{E}{s_i}{}=\frac{1}{2}\dpar{(t_i-s_i)^2}{s_i}{}=-(t_i-s_i)
  \end{align}
  %
\item Si la neurona $i$ se ubica en una capa oculta, el cálculo de
  $\dpar{E}{s_i}{}$ resulta más complejo. Aplicando nuevamente la
  regla de la cadena, se tiene:
  %
  \begin{align}\label{e2:deriv-E-wrt-s-hid} %mlp5
    \dpar{E}{s_i}{} \tab= \sum_{k\in\C{S}(i)}
      \dpar{E}{s_k}{}\dpar{s_k}{s_i}{} \notag\\
    \tab= \sum_{k\in\C{S}(i)}
      \dpar{E}{s_k}{}\dpar{s_k}{v_k}{}\dpar{v_k}{s_i}{} \notag\\
    \tab= \sum_{k\in\C{S}(i)} \dpar{E}{s_k}{} s'(v_k) w_{ki},
  \end{align}
  %
\end{itemize}
donde $\C{S}(i)$ denota el conjunto de todas las unidades $k$ en las
sucesivas capas para la cual la unidad $i$ tiene una conexión
pesada distinta de cero $w_{ki}$.

En la
\iflatexml{}Ecuación~\ref{e2:deriv-E-wrt-s-hid}\else\autoref{e2:deriv-E-wrt-s-hid}\fi
se asume que los valores $\dpar{E}{s_k}{}$ para todas las capas
sucesivas a la neurona $k$ es conocido. Ésta es la razón por la cual
el agoritmo comienza el cálculo de $\dpar{E}{s_k}{}$ en la capa de
salida
\iflatexml{}Ecuación~\ref{e2:deriv-E-wrt-s-hid}\else\autoref{e2:deriv-E-wrt-s-hid}\fi,
continuando con las capas ocultas en orden inverso.
%% Este requerimiento
%% se satisface simplemente comenzando el cálculo de $\dpar{E}{s_k}{}$ a
%% partir de la capa de salida (\refer{mlp4}) y luego continuar el cálculo
%% para las unidades en la capas pecedentes según la \refer{mlp5}.
Por ello se dice que la información del gradiente de error se propaga hacia atrás
a partir de la capa de salida hasta la primer capa
oculta. De allí el nombre `` retropropagación''.

El desarrollo del algoritmo de retropropagación a mediados de los años
80 representó un hito en el campo de las redes neuronales, ya
que brindó un método computacionalemnte eficiente, usable, para
entrenar el perceptrón multicapa.
%% %
%% \subsubsection{Descenso del gradiente}
%% %

En cada iteración $t=0,1,2,\ldots$, los pesos de la red
se modifican a lo largo de una dirección de búsqueda
$d(t)$ %, llevando los pesos en la dirección del mínimo estimado:
%
\begin{align}
  \Delta w(t)\tab=\epsilon * d(t), \tabs w(t+1) \tab= w(t)+\Delta w(t).
\end{align}
%
El parámetro $\epsilon$ es un número pequeño que escala la magnitud de
la modificación de los pesos y se denomina \e{velocidad de
aprendizaje}.  Para encontrar la dirección de búsqueda $d(t)$ se
utiliza el gradiente $\nabla{}E=\dpar{E}{w}{}$, calculado mediante el
algoritmo de retropropagación.



\hl{referencia al ajuste de los pesos mas arriba}
Una vez que se conocen las derivadas parciales, el paso siguiente en
el aprendizaje por retropropagación es calcular el ajuste resultante a
los pesos. En su forma más simple, la actualización de los pesos es un
paso escalado en la dirección opuesta al gradiente.  En otras
palabras, el negativo del gradiente se multiplica por una constante
pequeña $\epsilon$, la velocidad de aprendizaje. Esta técnica de
minimización se conoce comúnmente como el ``descenso del gradiente'':
%
\begin{align}\label{mlp6}
  \Delta w(t) = - \epsilon \nabla E(t),
\end{align}
%
o, para cada peso,
%
\begin{align}\label{mlp6}
  \Delta w_{ij}(t) = - \epsilon \dpar{E}{w_{ij}}{}(t).
\end{align}
%
Si bien la regla básica de aprendizaje es simple, con frecuencia
resulta difícil elegir en forma adecuada la velocidad de
aprendizaje. Una buena elección depende de la forma de la función de
error, que obviamente cambia con cada problema de aprendizaje
planteado, además de ser una función de dimensionalidad elevada.  Una
velocidad de aprendizaje pequeña resultará en un tiempo elevado de
convergencia en una función de error ``chata'', mientras que una velocidad
de aprendizaje grande posiblemente genere oscilaciones, previniendo
que el error caiga por debajo de un cierto valor.  Más aún, si bien la
convergencia a un mínimo local puede probarse en determinadas
circunstancias, no existen garantías que el algoritmo encuentre un
mínimo global de la función de error.

Otro problema con el descenso por gradiente es la influencia
``contraintuitiva'' de la derivada parcial sobre el tamaño del paso en
el ajuste de los pesos: si la función de error es ``playa'', la
derivada es relativamente pequeña, resultando en un paso pequeño.  Por
otro lado, ante la presencia de pendientes bruscas en la función de
la energía, en donde se deberían tomar pesos pequeños dada la
elevada pendiente, las derivadas ``grandes'' llevan a pasos grandes,
llevando posiblemente la búsqueda a una región completamente diferente
del espacio de los pesos.

\subsubsection{Término de momento}

Una idea para hacer el entrenamiento más estable es la adición de un
\e{término de momento}
%
\begin{align}\label{mlp8}
  \Delta w_{ij}(t) = - \epsilon \dpar{E}{w_{ij}}{}(t)
    + \mu \Delta w_{ij}(t-1).
\end{align}
%
El parámetro de momento $\mu$ escala la influencia del paso anterior
de actualización de los pesos en el paso actual. Esta técnica funciona
bien en muchas tareas de aprendizaje, aunque no significa un
incremento general de la estabilidad o de la velocidad de
convergencia.  A veces, el descenso de gradiente sin término de
momento obtiene iguales o mejores resultados que con el término de
momento. Usualmente, al utilizar aprendizaje con término de momento se
deberá disminuir la velocidad de aprendizaje para evitar inestabilidad
en el proceso de aprendizaje.

