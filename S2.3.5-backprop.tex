%
%
\subsection{El algoritmo de retropropagación}
%
El algoritmo de retropropagación es un algoritmo específico para el
perceptrón multicapa que efectúa entrenamiento ajustando los pesos
$w_{ij}$ de la red en el sentido que minimiza la función de error
$\C{E}$, a partir de la información obtenida del gradiente
$\nabla\C{E}=\dpar{\C{E}}{w_{ij}}{}$.

%% Aprovechando la arquitectura del MLP, el algoritmo de retropropagación
%% calcula el gradiente de la función de error comenzando por la capa de
%% salida y \e{propagando} el error $E$ en dirección inversa hasta la
%% primer capa oculta.

La idea básica del algoritmo de retropropagación es aplicar a cada
peso sináptico $w_{ij}(n)$ de la red una corrección
$\Delta{}w_{ij}(n)$ proporcional a la derivada parcial
$\dpar{\C{E}(n)}{w_{ij}}{}$.  Según la regla de la cadena, esta
derivada parcial puede escribirse
%
\begin{align}\label{e2:deriv-E-wrt-w-expanded}
  \dpar{\C{E}(n)}{w_{ij}}{} = \dpar{\C{E}(n)}{s_i(n)}{}
  \dpar{s_i(n)}{v_i(n)}{} \dpar{v_i(n)}{w_{ij}}{}.
\end{align}
%
Diferenciando ambos lados de la
\iflatexml{}Ecuación~\ref{e2:error-energy-neuron}
\else\autoref{e2:error-energy-neuron}\fi respecto de $s_i(n)$, se tiene
%
\begin{align}\label{e2:deriv-E-wrt-s}
  \dpar{\C{E}(n)}{s_i(n)}{} = -e_i(n).
\end{align}
%
Por la \iflatexml{}Ecuación~\ref{e2:neuron-general}
\else\autoref{e2:neuron-general}\fi, se tiene
%
\begin{align}\label{e2:deriv-s-wrt-v}
  \dpar{s_i(n)}{v_i(n)}{} \tab = f'(v_i(n)),\tabs
  \dpar{v_i(n)}{w_{ij}(n)}{} \tab = s_j(n).\\
\end{align}
%
Reemplazando las Ecuaciones
\ref{e2:deriv-E-wrt-s}--\ref{e2:deriv-s-wrt-v} en la
\iflatexml{}Ecuación~\ref{e2:deriv-E-wrt-w-expanded}
\else\autoref{e2:deriv-E-wrt-w-expanded}\fi, se tiene
%
\begin{align}\label{e2:deriv-E-wrt-w}
  \dpar{\C{E}(n)}{w_{ij}}{} = -e_i(n) f'(v_i(n)) s_j(n).
\end{align}
%
Cuando la neurona $i$ está en la capa de salida, esta fórmula se
utiliza directamente para el cálculo de $\dpar{\C{E}(n)}{w_{ij}}{}$,
ya que la señal de error $e_i(n)$ de la neurona viene dada por la
diferencia entre el valor deseado $y_k(n)$ y la salida de la neurona
$s_i(n)$ según la según la
\iflatexml{}Ecuación~\ref{e2:error-energy-neuron}
\else\autoref{e2:error-energy-neuron}\fi.

Sin embargo, las neuronas en las capas ocultas también deberán ajustar
sus pesos, ya que su valor de salida tiene influencia en la salida
global de la red, aunque resulta imposible determinar una ``respuesta
deseada'' correspondiente $y_k(n)$.  Por ello, cuando la neurona $i$
se ubica en una capa oculta, el cálculo de $\dpar{\C{E}(n)}{w_{ij}}{}$
resulta más complejo.  En particular, se desea obtener el valor de
$\dpar{\C{E}(n)}{s_i}{}$ correspondiente a una neurona en la capa
oculta.

El razonamiento para el cálculo de $\dpar{\C{E}(n)}{s_{i}}{}$, cuando
la neurona $i$ es oculta, es como sigue. Considérese en primer lugar
que el valor de $\dpar{\C{E}(n)}{s_k}{}$ es conocido, con
$k\in{}\C{S}(i)$, siendo $\C{S}(i)$ el conjunto de índices de todas
las neuronas en la capa siguiente a la capa de $i$.  Entonces, se
puede ver que
%
\begin{align}
  \dpar{\C{E}}{s_i}{} \tab= \sum_{k\in\C{S}(i)}
      \dpar{\C{E}}{s_k}{}\dpar{s_k}{s_i}{} \notag\\
    \tab= \sum_{k\in\C{S}(i)}
      \dpar{\C{E}}{s_k}{}\dpar{s_k}{v_k}{}\dpar{v_k}{s_i}{} \notag\\
    \tab= \sum_{k\in\C{S}(i)} \dpar{\C{E}}{s_k}{} s'(v_k) w_{ki}.
    \label{e2:deriv-E-wrt-s-hid}
\end{align}
%
Reemplazando la
\iflatexml{}Ecuación~\ref{e2:deriv-E-wrt-s-hid}\else\autoref{e2:deriv-E-wrt-s-hid}\fi
y la \iflatexml{}Ecuación~\ref{e2:deriv-s-wrt-v}
\else\autoref{e2:deriv-s-wrt-v}\fi en la 
\iflatexml{}Ecuación~\ref{e2:deriv-E-wrt-w-expanded}\else\autoref{e2:deriv-E-wrt-w-expanded}\fi,
se tiene entonces
%
\begin{align}\label{e2:deriv-E-wrt-w-hid}
  \dpar{\C{E}(n)}{w_{ij}}{} =
  \sum_{k\in\C{S}(i)} \dpar{\C{E}(n)}{s_k(n)}{} s'(v_k(n)) w_{ki}
  f'(v_i(n)) s_j(n).
\end{align}
%
Esta fórmula es la clave del algoritmo de retropropagación: por la
arquitectura del MLP, la salida $s_i(n)$ de una neurona oculta ejerce
una influencia en la salida de todas las neuronas en las capas
subsiguientes.  Del mismo modo, se tiene que el \e{gradiente local} de
la señal de error de la neurona viene determinado por los gradientes
de error de todas las neuronas en las capas subsiguientes.

Comenzando el cálculo de $\dpar{\C{E}(n)}{w_{ij}}{}$ por la capa de
salida
(\iflatexml{}Ecuación~\ref{e2:deriv-E-wrt-w}\else\autoref{e2:deriv-E-wrt-w}\fi)
y continuando con las capas ocultas en orden inverso
(\iflatexml{}Ecuación~\ref{e2:deriv-E-wrt-w-hid}\else\autoref{e2:deriv-E-wrt-w-hid}\fi),
el gradiente resulta calculable para todas las neuronas.  Por ello el
nombre `` retropropagación'': se dice que la información del gradiente
de error se propaga hacia atrás a partir de la capa de salida hasta la
primer capa oculta.

El desarrollo del algoritmo de retropropagación a mediados de los años
80 representó un hito en el campo de las redes neuronales, ya
que brindó un método computacionalemnte eficiente, usable, para
entrenar el perceptrón multicapa.
%
\subsubsection{Ajuste de los pesos de la red}
%
En cada paso del entrenamiento $n$, se calcula la salida de la red
$\B{s}(n)$ como respuesta a la entrada $\xx(n)$ y el gradiente
$\dpar{\C{E}(n)}{w_{ij}}{}$. A partir de la información del gradiente,
el algoritmo aplica una corrección $\Delta{}w_{ij}(n)$ sobre el peso
$w_{ij}(n)$ que viene dada por la ``regla delta''
%
\begin{align}\label{e2:delta-rule}
  \Delta w_{ij}(n)\tab=-\eta\dpar{\C{E}(n)}{w_{ij}}{},
\end{align}
%
en donde $\eta$ es el parámetro \e{velocidad de aprendizaje} del
algoritmo de retropropagación. La utilización del signo menos en la
\iflatexml{}Ecuación~\ref{e2:deriv-E-wrt-w}
\else\autoref{e2:deriv-E-wrt-w}\fi indica el \e{descenso por
  gradiente} en el espacio de los pesos $w_{ij}$. Esto implica que el
ajuste efectuado modifica los pesos en la dirección que reduce el
valor de $\C{E}(n)$.
%
\subsubsection{Entrenamiento por época}
%
La aplicación del algoritmo de retropropagación se adapta a una
estrategia de ajuste por época deriva de manera sencilla. Dada de la
definición de la energía de error promedio $\C{E}_{\T{av}}$ para la
época (\iflatexml{}Ecuación~\ref{e2:average-energy-net}\else\autoref{e2:average-energy-net}\fi),
se calculan las salidas $s(n)$ y los gradientes de error instantáneo
$\dpar{\C{E}(n)}{w_{ij}}{}$ para cada ejemplo $(\xx(n),\yy(n))$ en el
conjunto de entrenamiento. Entonces, el gradiente de error promedio
para la época viene dado por
%
\begin{align}\label{e2:deriv-Eav-wrt-w}
  \dpar{\C{E}_{\T{av}}(\ell)}{w_{ij}}{}\tab=
  \frac{1}{\ell}\sum_{n=1}^\ell\dpar{\C{E}(n)}{w_{ij}}{},
\end{align}
%
y la corrección a aplicar a los pesos viene dada por
%
\begin{align}\label{e2:delta-rule-epoch}
  \Delta w_{ij}(n)\tab=-\eta\dpar{\C{E}_{\T{av}}(\ell)}{w_{ij}}{}.
\end{align}
%
A diferencia del entrenamiento en línea, este ajuste se efectúa una
única vez al final de cada época. Dado que la función $\C{E}_{\T{av}}$
promedia todos los patrones de la época, la superficie de la función
de error probablemente será más ``suave'', y por lo tanto el gradiente
$\nabla\C{E}_{\T{av}}$ será numéricamente más estable, que en el caso
del error intantáneo.
%
\subsubsection{Criterio de corte}
%
En general, la convergencia del algoritmo de retropropagación no está
garantizada, y no existe un criterio de corte bien definido para
detener el entrenamiento. Algunos criterios razonables para establecer
la convergencia pueden ser:
%
\begin{itemize}
\item Cuando la norma del gradiente es muy pequeña
  ($\|\nabla\C{E}\|\leq\epsilon$), probablemente se deba a que se
  alcanzó un mínimo local de la función de error.
\item Cuando la función de energía promedio $\C{E}_{\T{av}}$ varía muy
  poco entre épocas, también podría significar que se alcanzó un
  mínimo local, indicando convergencia.
\end{itemize}
%
El problema de estos criterios es similar al de la velocidad de
aprendizaje: los valores de tolerancia a considerar para la
convergencia serán siempre dependientes del problema, y una elección
incorrecta puede llevar ya sea a un corte prematuro del entrenamiento,
o bien a que el algoritmo nunca converja.

Existe sin embargo un criterio de convergencia que tiene a la vez un
fundamento teórico y es independiente del conjunto de datos de
entrenamiento: luego de cada iteración de entrenamiento, se clasifica
un conjunto de prueba $T$
(\iflatexml{}Ecuación~\ref{eq:conj-prueba}\else\autoref{eq:conj-prueba}\fi),
obteniendo una estimación de error de generalización, y se detiene el
entrenamiento cuando se observa que este error es adecuado, o bien
cuando resulta evidente que ha alcanzado su mínimo. Esta estrategia es
la que se utiliza prácticamente en todas las implementaciones: incluso
cuando no se provee un conjunto de prueba separado, resulta común
reservar parte del conjunto de entrenamiento para estimar el error de
generalización.
