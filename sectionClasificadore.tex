\section{Clasificadores}
El objetivo de un clasificador es asignar una clase a un patrón de
entrada. En el presente caso, se trata de determinar si un patrón dado
se corresponde o no con el de un pre-microRNA.

En el ámbito de la Inteligencia Computacional, un clasificador
consiste en un \emph{modelo}, que se obtiene a partir de un proceso de
entrenamiento en que se presentan al clasificador patrones de entrada
con su correspondiente clase. En términos generales, la generación del
modelo requiere de la especificación de \emph{parámetros} propios del
algoritmo de entrenamiento, además de los patrones del conjunto de
entrenamiento y sus etiquetas. De este modo se obtiene un método de
clasificación que posee \emph{capacidad de generalización} a partir de
la representación interna del modelo obtenida durante el
entrenamiento, y puede clasificar incluso patrones que no le han sido
presentados en dicho proceso.

Los patrones de entrada al clasificador son vectores numéricos de
longitud fija que se obtienen mediante el proceso de extracción de
características de los datos de entrada originales. Este proceso ha
sido especificado en el Informe de Avance anteriormente presentado.

\subsection{Máquina de vectores de soporte}
La máquina de vectores de soporte (SVM, \eng{Support Vector Machine})
\cite{svm} es un clasificador binario que considera los patrones de
entrada como puntos en un espacio vectorial. Dada una función de transformación
$\BPhi(\cdot)\in{}\RR^N$, un clasificador SVM determina la clase $c$ de
un vector de entrada $\zz\in\RR^M$ mediante

\begin{align}
  c &= \T{sgn}{\left(\ww\cdot\BPhi(\zz)+b\right)},
\end{align}
donde sgn es la función signo, y $\ww,b$ se obtienen de resolver el
problema de optimización

\begin{align}
  \min_{\ww,b} &\quad
  \frac{1}{2}(\ww\cdot\ww)+C\sum_{i=1}^{l}\xi_i\\
  \T{sujeto a} &\quad
  y_i(\ww\cdot\BPhi(\xx_i)+b)\geq 1-\xi_i,\\
  &\quad\xi_i\geq 0,
\end{align}
donde $(\xx_i,y_i), i=1,\ldots,l$ es el conjunto de pares
vector-clase de entrenamiento, $\xi_i$ es el error cometido al
clasificar el $i$-ésimo patrón, y $C\geq0$ es una constante que
determina la tolerancia a dichos errores de clasificación.

En la práctica, el problema se resuelve mediante una formulación
dual \cite{bottou}, determinando
coeficientes $b$ y $\alpha_i\geq0$ tales que $\ww=\sum_{i=1}^l
y_i\alpha_i\BPhi(\xx_i)$, y la función de clasificación queda
definida como

\begin{align}
  c &= \T{sgn}\left(\sum_{i=1}^l
  y_i\alpha_i\left(\BPhi(\xx_i)\cdot\BPhi(\zz)\right)+b\right) =
  \T{sgn}\left(\sum_{i=1}^l y_i\alpha_iK(\xx_i,\zz)+b\right).
\end{align}
Aquellos vectores de entrenamiento $\xx_i$ para los que $\alpha_i >
0$ se denominan \emph{vectores de soporte}, de ahí el nombre del
clasificador.  La función
$K(\xx,\zz)=\BPhi(\xx)\cdot\BPhi(\zz)$, denominada
\eng{kernel}, determina la similaridad entre los vectores $\xx$ y
$\zz$ en el espacio transformado mediante un resultado escalar. En
este trabajo se consideran las siguientes funciones:

\begin{description}
  [style=sameline,leftmargin=5cm,itemsep=6pt,align=right]
  \item[Lineal:] $K(\xx,\zz)=\xx\cdot\zz$, el caso
    más sencillo donde $K$ es simplemente el producto escalar entre
    sus argumentos.
\item[RBF:] $K(\xx,\zz)=e^{(-\gamma||\xx-\zz||^2)}$,
  denominada función de base radial (RBF, \eng{Radial Basis
    Function}), requiere de la especificación del valor $\gamma>0$.
\end{description}
Se tiene entonces que los parámetros necesarios para la generación del
modelo SVM son el tipo de kernel a utilizar y sus parámetros, y el
valor $C$ que penaliza los errores de clasificación.