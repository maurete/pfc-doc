%
\subsubsection{Validación cruzada dejando uno fuera}
%
La validación cruzada dejando uno fuera (\e{leave-one-out}) es el caso
especial cuando se establece el número de particiones $k$ igual al
número de elementos $\ell$ en el conjunto de entrenamiento $D$.  El
modelo obtenido en cada iteración será muy similar al resultante de
entrenar con el conjunto de datos completo, por lo que es de esperar
que la estimación del error obtenida en este caso sea lo más cercana
al comportamiento ``real'' del modelo final entrenado sobre $D$.

La importancia de este procedimiento reside en el hecho que es el
mejor estimador del error real de la máquina de aprendizaje.  En
general, no se utiliza en la práctica debido a su elevado costo
computacional, ya que se requieren $\ell$ entrenamientos para su
cálculo.  Sin embargo, en determinados casos específicos existen
técnicas eficientes para su cálculo \cite{chapelle,lee-keerthi}.
